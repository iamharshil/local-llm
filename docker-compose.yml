services:
  llm-api:
    build: .
    container_name: local-llm-api
    ports:
      - "8000:8000"
    volumes:
      - ./models:/app/models
      - ./data:/app/data
      - ./hf-cache:/root/.cache/huggingface     # <--- ADD THIS
    environment:
      - MODEL_PATH=/app/models/mistral.gguf

  llm-train:
    build: .
    container_name: local-llm-train
    command: ["python", "train/train.py"]
    volumes:
      - ./models:/app/models
      - ./data:/app/data
      - ./hf-cache:/root/.cache/huggingface     # <--- ADD THIS
