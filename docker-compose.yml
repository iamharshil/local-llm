services:
  llm-train:
    build: .
    container_name: local-llm-train
    command: ["python3", "train/train.py"]
    volumes:
      - ./models:/app/models
      - ./data:/app/data
      - ./hf-cache:/root/.cache/huggingface

  llm-convert:
    build: .
    container_name: local-llm-convert
    command: ["python3", "train/convert_to_gguf.py"]
    volumes:
      - ./models:/app/models

  llm-api:
    build: .
    container_name: local-llm-api
    depends_on:
      - llm-convert
    ports:
      - "8000:8000"
    volumes:
      - ./models:/app/models
